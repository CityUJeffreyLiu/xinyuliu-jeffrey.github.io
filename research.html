<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="baidu-site-verification" content="YRqeInIxFa" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Xinyu Liu's Homepage</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
	<b>Menu</b> <HR>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="publication.html">Publication</a></div>
    <b>Link</b> <HR>
<div class="menu-item"><a href="CV_XinyuLiu.pdf" target ="_blank">Curriculum Vitae</a></div>
<!-- <div class="menu-item"><a href="album.html">Album</a></div> -->



<td id="layout-content">
<div id="toptitle">
<h1>Research</h1>
</div>
<h2>Real Time Instance Segmentation Method For Industrial Welding Spots</h2>
<p>In real industrial manufacturing scenarios, computer vision inspection algorithms is usually utilized for recognizing the locations and 
	shapes of the laser welding spots. Meanwhile, it is also essential to detect the defects of these spots. In order to realize a fully
	automated detection pipeline, we proposed an anchor-free instance segmentation method and implemented on our labelled dataset. Our 
	method can not only classify and locate the welding spots accurately, but also record the amount of instances in each image. More experiments
	are being taken, and a manuscript is in preparation.
</p>
<table class="imgtable"><tr><td>
<img src="photos/backtab.png" alt="alt text" width="500px" />
<img src="photos/fronttab.png" alt="alt text" width="500px" /></td></tr>
</table>
<p>The pictures plot the segmented results under the proposed algorithms in [1] (back tab and front tab, respectively).</p>
<p><b>Related Publications:</b></p>
<p>[1] <b>X. Liu</b>, and X. Di, &ldquo;An Anchor-free Instance Segmentation Pipeline For Industrial Welding Spots,&rdquo; 2020. In preparation.</p>
<p><b>Related Code:</b></p>
<p>[1] <a href="https://github.com/xinyuliu-jeffrey/WeldingSpotSegmentation" target ="_blank">WeldingSpotSegmentation</a><br /></p>

<h2>Developing A Novel Activation Function For Image Classification</h2>
<p>With the development of Deep Neural Networks, researchers tend to find out the most effective method of realizing the non-linearity, thus an exploration of activation
	function is continuously in process. In this work, we present a novel simple yet effective activation function named Tanh Exponential Activation Function(TanhExp). TanhExp is a smooth function that is not 
	piecewise. It is continuous, unbounded above and bounded below, with a minimum value of -0.3533. The positive half is approximately linear, which ensures the network preserves
	the distribution of original data to some extent. Besides, TanhExp requires less computation than other smooth functions and does not need any hyper-parameters, which has
	little effect on the size and training speed of the network. TanhExp is also easy to implement, with just a few modifications to each model. We demonstrate the simplicity and
	effectiveness of TanhExp on various datasets and network models and TanhExp outperforms its counterparts in both accuracy and convergence speed, especially on light networks. For instance, on a 15-layer neural network, the test
	accuracy of TanhExp at the first epoch is 36% higher than Mish and 123% higher than Swish. We believe that TanhExp will definitely benefit researchers on many tasks.</p>
<table class="imgtable"><tr><td>
<img src="photos/accuracy.png" alt="alt text" width="400px" /></td>
<td><img src="photos/loss.png" alt="alt text" width="400px" /></td></tr>
</table>
<p>The pictures plot the accuracy and loss in Fasion Mnist of our proposed activation function in [1].</p>

<p><b>Related Publications:</b></p>
<p>[1] <b>X. Liu</b>, and X. Di, &ldquo;TanhExp: A Smooth Activation Function with High Convergence Speed,&rdquo; Submitted, 2019.</p> 



<h2>Enhance Semantic Segmentation Results Through Merging Multi-Scale Features</h2>
<p>Current semantic segmentation methods are always suffering from the dilemma between classification and localization and 
	the effectiveness of utilizing a classification architecture as a network backbone. We propose a Multi-Scale Recurrent Network (MSRNet) which aims at alleviating
	the above issues. Specifically, we propose Spatial Pyramid Recurrent module (SPR) to capture classification and localization features simultaneously based on spatial pyramid structure, in which 
	ConvLSTM is used for extracting the relations we discovered among multi-scale feature maps. We also
	propose a Feature Fusion module to fuse the features between large and small feature maps through
	attention mechanism. Besides, we apply Semantic Classification Loss into SPR module in order to
	force the smallest feature map to concentrate on classification and avoid the impact of a variety of sizes
	of objects. Finally, we demonstrate the validity and flexibility of MSRNet and Deeplab v3+ added
	with our proposed modules on Pascal VOC 2012 dataset, which shows a significant improvement in
	both accuracy and mean IOU.
</p>

<table class="imgtable"><tr><td>
<img src="photos/msrnet.png" alt="alt text" width="500px" />
</td>
</table>
<p>The pictures represent the ground truth and our results in [1].</p>

<p><b>Related Publications:</b></p>
<p>[1] H. Zhang, X. Di and <b>X. Liu</b>, &ldquo;Merging Multi-Scale Features through Recurrent Neural Network for
	Semantic Segmentation,&rdquo; Submitted, 2019. </p>
